{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('dataset/iris.data')\n",
    "df = pd.read_csv(p)\n",
    "feature_cols = ['sepal_length', 'sepal_width','petal_length','petal_witdh']\n",
    "target_cols = ['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(data.Dataset):\n",
    "    def __init__(\n",
    "            self, path:str, feature_cols:list, \n",
    "            target_cols:list, clazz:list, \n",
    "            transforms_feature=None, transforms_target=None):\n",
    "        \n",
    "        self.path = Path(path)\n",
    "        self.dframe = pd.read_csv(self.path)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        self.clazz = clazz\n",
    "        self.transforms_feature = transforms_feature\n",
    "        self.transforms_target = transforms_target\n",
    "        \n",
    "        self.__normalize_target()\n",
    "        self.class_to_idx = self.__class_to_label()\n",
    "        self.idx_to_class = self.__idx_to_class()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dframe)\n",
    "    \n",
    "    def __class_to_label(self):\n",
    "        mapz = [(val, idx) for idx, val in enumerate(self.clazz)]\n",
    "        return dict(mapz)\n",
    "    \n",
    "    def __idx_to_class(self):\n",
    "        mapz = [(idx, val) for idx, val in enumerate(self.clazz)]\n",
    "        return dict(mapz)\n",
    "    \n",
    "    def __normalize_target(self):\n",
    "        cat_type = CategoricalDtype(categories=self.clazz, ordered=True)\n",
    "        self.dframe[self.target_cols[0]] = self.dframe[self.target_cols[0]].astype(cat_type).cat.codes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.dframe[self.feature_cols].iloc[idx].values\n",
    "        target = self.dframe[self.target_cols].iloc[idx].values\n",
    "        target = np.squeeze(target)\n",
    "        \n",
    "        if self.transforms_feature:\n",
    "            feature = self.transforms_feature(feature)\n",
    "        if self.transforms_target:\n",
    "            target = self.transforms_target(target)\n",
    "            \n",
    "        return feature, target\n",
    "\n",
    "\n",
    "def indice_splitter(dataset, valid_size, shuflle=True):\n",
    "    num_data = len(dataset)\n",
    "    indices = list(range(num_data))\n",
    "    split = int(np.floor(valid_size * num_data))\n",
    "    if shuflle:\n",
    "        np.random.seed(1)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "class NumpyToFloatTensor(object):\n",
    "    def __call__(self, param):\n",
    "        return torch.from_numpy(param.astype(np.float32)).float()\n",
    "\n",
    "class NumpyToLongTensor(object):\n",
    "    def __call__(self, param):\n",
    "        return torch.from_numpy(param.astype(np.long)).long()\n",
    "\n",
    "        \n",
    "        \n",
    "path = 'dataset/iris.data'\n",
    "feature_cols = ['sepal_length', 'sepal_width','petal_length','petal_witdh']\n",
    "target_cols = ['class']\n",
    "clazz = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
    "\n",
    "iris_dataset = IrisDataset(\n",
    "    path, feature_cols, \n",
    "    target_cols, clazz, \n",
    "    transforms_feature=NumpyToFloatTensor(), transforms_target=NumpyToLongTensor())\n",
    "\n",
    "train_idx, valid_idx = indice_splitter(iris_dataset, valid_size=0.2)\n",
    "\n",
    "train_loader = data.DataLoader(iris_dataset, batch_size=32, sampler=SubsetRandomSampler(train_idx), num_workers=0)\n",
    "valid_loader = data.DataLoader(iris_dataset, batch_size=32, sampler=SubsetRandomSampler(valid_idx), num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
